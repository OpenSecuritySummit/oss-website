---
title        : "Technics to limit hallucinations when using a LLM solution like ChatGPT"
track        : Governance
project      : Risk and Governance
type         : working-session
topics       : 
featured     :
event        : mini-summit
when_year    : 2024
when_month   : Jan
when_day     : Thu
when_time    : WS-17-18
hey_summit   : https://us06web.zoom.us/meeting/register/tZUucuivqzwoHNHCUYqioU_JiA7I0_B6LzSt
session_slack:
#status      : draft
description  :
banner       : https://github.com/OpenSecuritySummit/oss-website/blob/main/content/sessions/2024/mini-summits/Jan/banners/Technics%20to%20limit%20hallucination.jpeg?raw=true
organizers   :
     - Matthew Thompson
    
youtube_link : https://youtu.be/mJ4hMUK6sXI
zoom_link    : https://us06web.zoom.us/meeting/register/tZUucuivqzwoHNHCUYqioU_JiA7I0_B6LzSt
---

## About this session
Join us in an exciting session with Matthew Thompson as he delves into the innovative world of Large Language Models (LLM) like ChatGPT. Discover effective techniques to limit hallucinations and false data generation, ensuring that your use of these advanced tools remains accurate, reliable, and effective.

In this session, Matthew will share his deep insights and practical strategies to help you navigate the challenges and maximize the potential of AI-driven solutions. Whether you are a technology enthusiast, a developer, or a cybersecurity professional, this session will equip you with the knowledge to harness the power of LLMs responsibly and innovatively.

Learn from an expert in the field and be part of the conversation shaping the future of AI and cybersecurity. Reserve your spot now for this insightful session on January 18th, 2024!
